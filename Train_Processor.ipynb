{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 # 使⽤45%記憶體\n",
    "# set_session(tf.Session()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66787 16697\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "image_path = [\"../DeepLearning/kermany2018/NewSize/train/CNV\", \n",
    "              \"../DeepLearning/kermany2018/NewSize/train/DME\",\n",
    "              \"../DeepLearning/kermany2018/NewSize/train/DRUSEN\",\n",
    "              \"../DeepLearning/kermany2018/NewSize/train/NORMAL\"]\n",
    "#image_path = [\"./data/A\", \"./data/B\"]\n",
    "\n",
    "def preprocess_to_data_file(data_dir_list, ratio=0.8):\n",
    "\n",
    "    total_list = [] \n",
    "   \n",
    "    '''\n",
    "        create all images into (image path, label) format and write to total_data.txt \n",
    "    ''' \n",
    "    with open('total_data.txt', 'w') as f:\n",
    "        for index, data_dir in enumerate(data_dir_list):\n",
    "            for filename in listdir(data_dir):\n",
    "                #print(\"{} {}\".format(data_dir_list[index]+'/'+filename, index))\n",
    "                f.write('{} {}\\n'.format(data_dir_list[index]+'/'+filename.replace(' ',''), index))\n",
    "                total_list.append(data_dir_list[index]+'/'+filename.replace(' ','')+' '+str(index))\n",
    "\n",
    "    #print(total_list)\n",
    "    '''\n",
    "        shuffle total_list\n",
    "    ''' \n",
    "    shuffle(total_list)\n",
    "\n",
    "    '''\n",
    "        split total_list to train_list and test_list. \n",
    "        write train_list/test_list into train_data.txt/test_data.txt\n",
    "    ''' \n",
    "    train_list = total_list[:int(ratio*len(total_list))]\n",
    "    test_list = total_list[int(ratio*len(total_list)):]\n",
    "    print(len(train_list),len(test_list))\n",
    "\n",
    "    with open('train_data.txt', 'w') as f:\n",
    "        for i in train_list:\n",
    "            f.write(i+'\\n')\n",
    "\n",
    "    with open('test_data.txt', 'w') as f:\n",
    "        for i in test_list:\n",
    "            f.write(i+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "preprocess_to_data_file(image_path, 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image path......\n",
      "number of train image is 66787\n",
      "number of test image is 16697\n",
      "start training......\n",
      "step=0, loss=25.995214462280273, accuracy=0.1171875\n",
      "test accuracy = 0.43549999594688416\n",
      "step=100, loss=1.5034153461456299, accuracy=0.33203125\n",
      "test accuracy = 0.30149999260902405\n",
      "step=200, loss=2.3095462322235107, accuracy=0.43359375\n",
      "test accuracy = 0.4465000033378601\n",
      "step=300, loss=2.0140233039855957, accuracy=0.43359375\n",
      "test accuracy = 0.3154999911785126\n",
      "step=400, loss=1.2382534742355347, accuracy=0.46484375\n",
      "test accuracy = 0.4675000011920929\n",
      "step=500, loss=2.731905937194824, accuracy=0.4921875\n",
      "test accuracy = 0.4724999964237213\n",
      "step=600, loss=1.7527737617492676, accuracy=0.30859375\n",
      "test accuracy = 0.4065000116825104\n",
      "step=700, loss=1.170323133468628, accuracy=0.54296875\n",
      "test accuracy = 0.492000013589859\n",
      "step=800, loss=1.1742198467254639, accuracy=0.55078125\n",
      "test accuracy = 0.5065000057220459\n",
      "step=900, loss=2.805194854736328, accuracy=0.1875\n",
      "test accuracy = 0.4494999945163727\n",
      "step=1000, loss=1.168479323387146, accuracy=0.5\n",
      "test accuracy = 0.4165000021457672\n",
      "step=1100, loss=1.2846877574920654, accuracy=0.37890625\n",
      "test accuracy = 0.41749998927116394\n",
      "step=1200, loss=1.1730964183807373, accuracy=0.51953125\n",
      "test accuracy = 0.5354999899864197\n",
      "step=1300, loss=1.436237096786499, accuracy=0.3828125\n",
      "test accuracy = 0.4794999957084656\n",
      "step=1400, loss=1.7009938955307007, accuracy=0.2109375\n",
      "test accuracy = 0.2475000023841858\n",
      "step=1500, loss=1.1651197671890259, accuracy=0.48828125\n",
      "test accuracy = 0.5715000033378601\n",
      "step=1600, loss=1.9787288904190063, accuracy=0.39453125\n",
      "test accuracy = 0.5630000233650208\n",
      "step=1700, loss=1.2334811687469482, accuracy=0.51953125\n",
      "test accuracy = 0.5870000123977661\n",
      "step=1800, loss=1.0281505584716797, accuracy=0.59765625\n",
      "test accuracy = 0.49050000309944153\n",
      "step=1900, loss=1.1806994676589966, accuracy=0.53125\n",
      "test accuracy = 0.6179999709129333\n",
      "step=2000, loss=0.9910711050033569, accuracy=0.60546875\n",
      "test accuracy = 0.5839999914169312\n",
      "step=2100, loss=1.15445876121521, accuracy=0.625\n",
      "test accuracy = 0.578000009059906\n",
      "step=2200, loss=0.990574836730957, accuracy=0.6171875\n",
      "test accuracy = 0.628000020980835\n",
      "step=2300, loss=0.9895572662353516, accuracy=0.6328125\n",
      "test accuracy = 0.5914999842643738\n",
      "step=2400, loss=0.9423706531524658, accuracy=0.66796875\n",
      "test accuracy = 0.6244999766349792\n",
      "step=2500, loss=0.8632599115371704, accuracy=0.65234375\n",
      "test accuracy = 0.6269999742507935\n",
      "step=2600, loss=0.9594489932060242, accuracy=0.6484375\n",
      "test accuracy = 0.659500002861023\n",
      "step=2700, loss=0.8937814235687256, accuracy=0.66796875\n",
      "test accuracy = 0.6154999732971191\n",
      "step=2800, loss=0.9715715646743774, accuracy=0.6484375\n",
      "test accuracy = 0.659500002861023\n",
      "step=2900, loss=0.9137922525405884, accuracy=0.6796875\n",
      "test accuracy = 0.5945000052452087\n",
      "step=3000, loss=1.028397560119629, accuracy=0.66796875\n",
      "test accuracy = 0.6414999961853027\n",
      "step=3100, loss=1.129756212234497, accuracy=0.60546875\n",
      "test accuracy = 0.6244999766349792\n",
      "step=3200, loss=0.9328237771987915, accuracy=0.6328125\n",
      "test accuracy = 0.6934999823570251\n",
      "step=3300, loss=0.8073995113372803, accuracy=0.70703125\n",
      "test accuracy = 0.6710000038146973\n",
      "step=3400, loss=0.9304736852645874, accuracy=0.68359375\n",
      "test accuracy = 0.6485000252723694\n",
      "step=3500, loss=0.8103963136672974, accuracy=0.69140625\n",
      "test accuracy = 0.6600000262260437\n",
      "step=3600, loss=0.8521004319190979, accuracy=0.6953125\n",
      "test accuracy = 0.6930000185966492\n",
      "step=3700, loss=0.8022813200950623, accuracy=0.69921875\n",
      "test accuracy = 0.7020000219345093\n",
      "step=3800, loss=0.7716598510742188, accuracy=0.69921875\n",
      "test accuracy = 0.6840000152587891\n",
      "step=3900, loss=1.014284610748291, accuracy=0.6640625\n",
      "test accuracy = 0.6945000290870667\n",
      "step=4000, loss=0.765789270401001, accuracy=0.73046875\n",
      "test accuracy = 0.6779999732971191\n",
      "step=4100, loss=0.9031118750572205, accuracy=0.671875\n",
      "test accuracy = 0.7085000276565552\n",
      "step=4200, loss=0.7821791768074036, accuracy=0.6875\n",
      "test accuracy = 0.6754999756813049\n",
      "step=4300, loss=0.9093160629272461, accuracy=0.69921875\n",
      "test accuracy = 0.6815000176429749\n",
      "step=4400, loss=0.8006076812744141, accuracy=0.71484375\n",
      "test accuracy = 0.671999990940094\n",
      "step=4500, loss=0.7126027345657349, accuracy=0.73046875\n",
      "test accuracy = 0.7260000109672546\n",
      "step=4600, loss=0.7841833829879761, accuracy=0.6953125\n",
      "test accuracy = 0.7049999833106995\n",
      "step=4700, loss=0.8515306115150452, accuracy=0.66015625\n",
      "test accuracy = 0.7059999704360962\n",
      "step=4800, loss=0.6944385766983032, accuracy=0.72265625\n",
      "test accuracy = 0.718999981880188\n",
      "step=4900, loss=0.7852256894111633, accuracy=0.71875\n",
      "test accuracy = 0.7289999723434448\n",
      "step=5000, loss=0.7529085874557495, accuracy=0.7265625\n",
      "test accuracy = 0.7055000066757202\n",
      "step=5100, loss=0.7570000886917114, accuracy=0.7265625\n",
      "test accuracy = 0.7179999947547913\n",
      "step=5200, loss=0.8426660299301147, accuracy=0.6953125\n",
      "test accuracy = 0.718999981880188\n",
      "step=5300, loss=0.670940637588501, accuracy=0.74609375\n",
      "test accuracy = 0.7129999995231628\n",
      "step=5400, loss=0.7300234436988831, accuracy=0.73046875\n",
      "test accuracy = 0.6884999871253967\n",
      "step=5500, loss=0.5901453495025635, accuracy=0.74609375\n",
      "test accuracy = 0.7149999737739563\n",
      "step=5600, loss=0.8590589761734009, accuracy=0.69921875\n",
      "test accuracy = 0.6940000057220459\n",
      "step=5700, loss=0.6120964288711548, accuracy=0.7734375\n",
      "test accuracy = 0.737500011920929\n",
      "step=5800, loss=0.6674568057060242, accuracy=0.73046875\n",
      "test accuracy = 0.7074999809265137\n",
      "step=5900, loss=0.6024825572967529, accuracy=0.75390625\n",
      "test accuracy = 0.7329999804496765\n",
      "step=6000, loss=0.7988928556442261, accuracy=0.68359375\n",
      "test accuracy = 0.7229999899864197\n",
      "step=6100, loss=0.5925080180168152, accuracy=0.7734375\n",
      "test accuracy = 0.7279999852180481\n",
      "step=6200, loss=0.8538356423377991, accuracy=0.73828125\n",
      "test accuracy = 0.7310000061988831\n",
      "step=6300, loss=0.6735695600509644, accuracy=0.75390625\n",
      "test accuracy = 0.6995000243186951\n",
      "step=6400, loss=0.6236394047737122, accuracy=0.7578125\n",
      "test accuracy = 0.7440000176429749\n",
      "step=6500, loss=0.6868224143981934, accuracy=0.7578125\n",
      "test accuracy = 0.7360000014305115\n",
      "step=6600, loss=0.6284933686256409, accuracy=0.76171875\n",
      "test accuracy = 0.7160000205039978\n",
      "step=6700, loss=0.6710610389709473, accuracy=0.734375\n",
      "test accuracy = 0.7534999847412109\n",
      "step=6800, loss=0.6086614727973938, accuracy=0.7578125\n",
      "test accuracy = 0.7444999814033508\n",
      "step=6900, loss=0.7849074006080627, accuracy=0.71875\n",
      "test accuracy = 0.7064999938011169\n",
      "step=7000, loss=0.5675103068351746, accuracy=0.76171875\n",
      "test accuracy = 0.7599999904632568\n",
      "step=7100, loss=0.5459575653076172, accuracy=0.8125\n",
      "test accuracy = 0.7369999885559082\n",
      "step=7200, loss=0.564792275428772, accuracy=0.796875\n",
      "test accuracy = 0.7555000185966492\n",
      "step=7300, loss=0.6654740571975708, accuracy=0.7421875\n",
      "test accuracy = 0.7595000267028809\n",
      "step=7400, loss=0.5182095766067505, accuracy=0.82421875\n",
      "test accuracy = 0.7409999966621399\n",
      "step=7500, loss=0.574637234210968, accuracy=0.78125\n",
      "test accuracy = 0.7584999799728394\n",
      "step=7600, loss=0.6501340866088867, accuracy=0.73046875\n",
      "test accuracy = 0.7534999847412109\n",
      "step=7700, loss=0.5180692076683044, accuracy=0.79296875\n",
      "test accuracy = 0.7505000233650208\n",
      "step=7800, loss=0.6513471007347107, accuracy=0.75\n",
      "test accuracy = 0.7605000138282776\n",
      "step=7900, loss=0.4985661208629608, accuracy=0.796875\n",
      "test accuracy = 0.7559999823570251\n",
      "step=8000, loss=0.5593327283859253, accuracy=0.7578125\n",
      "test accuracy = 0.7609999775886536\n",
      "step=8100, loss=0.44723713397979736, accuracy=0.8515625\n",
      "test accuracy = 0.7605000138282776\n",
      "step=8200, loss=0.5859212875366211, accuracy=0.76171875\n",
      "test accuracy = 0.737500011920929\n",
      "step=8300, loss=0.5047601461410522, accuracy=0.78515625\n",
      "test accuracy = 0.7664999961853027\n",
      "step=8400, loss=0.45008644461631775, accuracy=0.84375\n",
      "test accuracy = 0.7605000138282776\n",
      "step=8500, loss=0.552413821220398, accuracy=0.77734375\n",
      "test accuracy = 0.7739999890327454\n",
      "step=8600, loss=0.5093867182731628, accuracy=0.80078125\n",
      "test accuracy = 0.7705000042915344\n",
      "step=8700, loss=0.5014494061470032, accuracy=0.80859375\n",
      "test accuracy = 0.7549999952316284\n",
      "step=8800, loss=0.5002202987670898, accuracy=0.796875\n",
      "test accuracy = 0.7680000066757202\n",
      "step=8900, loss=0.6548304557800293, accuracy=0.7578125\n",
      "test accuracy = 0.7549999952316284\n",
      "step=9000, loss=0.5540328025817871, accuracy=0.78125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 0.7754999995231628\n",
      "step=9100, loss=0.5460309982299805, accuracy=0.76953125\n",
      "test accuracy = 0.7519999742507935\n",
      "step=9200, loss=0.4035431444644928, accuracy=0.84375\n",
      "test accuracy = 0.7689999938011169\n",
      "step=9300, loss=0.4135703444480896, accuracy=0.83203125\n",
      "test accuracy = 0.7749999761581421\n",
      "step=9400, loss=0.5283043384552002, accuracy=0.80859375\n",
      "test accuracy = 0.7770000100135803\n",
      "step=9500, loss=0.45055079460144043, accuracy=0.83984375\n",
      "test accuracy = 0.7799999713897705\n",
      "step=9600, loss=0.5050524473190308, accuracy=0.80078125\n",
      "test accuracy = 0.7864999771118164\n",
      "step=9700, loss=0.40723755955696106, accuracy=0.83984375\n",
      "test accuracy = 0.7835000157356262\n",
      "step=9800, loss=0.4916848838329315, accuracy=0.80078125\n",
      "test accuracy = 0.7754999995231628\n",
      "step=9900, loss=0.4205305874347687, accuracy=0.8515625\n",
      "test accuracy = 0.784500002861023\n",
      "step=10000, loss=0.4520394504070282, accuracy=0.79296875\n",
      "test accuracy = 0.7730000019073486\n",
      "step=10100, loss=0.4645250141620636, accuracy=0.81640625\n",
      "test accuracy = 0.7919999957084656\n",
      "step=10200, loss=0.49437806010246277, accuracy=0.796875\n",
      "test accuracy = 0.7975000143051147\n",
      "step=10300, loss=0.5453874468803406, accuracy=0.8203125\n",
      "test accuracy = 0.7864999771118164\n",
      "step=10400, loss=0.4303835928440094, accuracy=0.82421875\n",
      "test accuracy = 0.7645000219345093\n",
      "step=10500, loss=0.3717309236526489, accuracy=0.8828125\n",
      "test accuracy = 0.7864999771118164\n",
      "step=10600, loss=0.3999266028404236, accuracy=0.84765625\n",
      "test accuracy = 0.7900000214576721\n",
      "step=10700, loss=0.5746978521347046, accuracy=0.78515625\n",
      "test accuracy = 0.7764999866485596\n",
      "step=10800, loss=0.4797758162021637, accuracy=0.81640625\n",
      "test accuracy = 0.7990000247955322\n",
      "step=10900, loss=0.4524875283241272, accuracy=0.859375\n",
      "test accuracy = 0.7820000052452087\n",
      "step=11000, loss=0.45785632729530334, accuracy=0.80078125\n",
      "test accuracy = 0.7950000166893005\n",
      "step=11100, loss=0.5232111215591431, accuracy=0.82421875\n",
      "test accuracy = 0.7979999780654907\n",
      "step=11200, loss=0.4012262225151062, accuracy=0.84765625\n",
      "test accuracy = 0.796999990940094\n",
      "step=11300, loss=0.39303404092788696, accuracy=0.8203125\n",
      "test accuracy = 0.7730000019073486\n",
      "step=11400, loss=0.4272719919681549, accuracy=0.859375\n",
      "test accuracy = 0.7835000157356262\n",
      "step=11500, loss=0.4449143409729004, accuracy=0.83984375\n",
      "test accuracy = 0.7950000166893005\n",
      "step=11600, loss=0.3697134256362915, accuracy=0.87109375\n",
      "test accuracy = 0.7929999828338623\n",
      "step=11700, loss=0.39714956283569336, accuracy=0.84765625\n",
      "test accuracy = 0.7459999918937683\n",
      "step=11800, loss=0.34446269273757935, accuracy=0.87890625\n",
      "test accuracy = 0.7954999804496765\n",
      "step=11900, loss=0.41837427020072937, accuracy=0.8359375\n",
      "test accuracy = 0.8034999966621399\n",
      "step=12000, loss=0.4499934911727905, accuracy=0.85546875\n",
      "test accuracy = 0.7850000262260437\n",
      "step=12100, loss=0.5351512432098389, accuracy=0.77734375\n",
      "test accuracy = 0.7695000171661377\n",
      "step=12200, loss=0.3795856833457947, accuracy=0.87109375\n",
      "test accuracy = 0.7785000205039978\n",
      "step=12300, loss=0.43571189045906067, accuracy=0.81640625\n",
      "test accuracy = 0.8069999814033508\n",
      "step=12400, loss=0.5025138854980469, accuracy=0.84765625\n",
      "test accuracy = 0.7979999780654907\n",
      "step=12500, loss=0.45707908272743225, accuracy=0.828125\n",
      "test accuracy = 0.7954999804496765\n",
      "step=12600, loss=0.3992006182670593, accuracy=0.84765625\n",
      "test accuracy = 0.7975000143051147\n",
      "step=12700, loss=0.3950158655643463, accuracy=0.87890625\n",
      "test accuracy = 0.8040000200271606\n",
      "step=12800, loss=0.3658786416053772, accuracy=0.875\n",
      "test accuracy = 0.7950000166893005\n",
      "step=12900, loss=0.448271244764328, accuracy=0.86328125\n",
      "test accuracy = 0.7990000247955322\n",
      "step=13000, loss=0.36035773158073425, accuracy=0.86328125\n",
      "test accuracy = 0.7699999809265137\n",
      "step=13100, loss=0.3640291094779968, accuracy=0.8828125\n",
      "test accuracy = 0.7914999723434448\n",
      "step=13200, loss=0.42269277572631836, accuracy=0.83203125\n",
      "test accuracy = 0.8054999709129333\n",
      "step=13300, loss=0.40100669860839844, accuracy=0.859375\n",
      "test accuracy = 0.7770000100135803\n",
      "step=13400, loss=0.4313352704048157, accuracy=0.83984375\n",
      "test accuracy = 0.7795000076293945\n",
      "step=13500, loss=0.43293243646621704, accuracy=0.83984375\n",
      "test accuracy = 0.7820000052452087\n",
      "step=13600, loss=0.4692456126213074, accuracy=0.8203125\n",
      "test accuracy = 0.8015000224113464\n",
      "step=13700, loss=0.3966948986053467, accuracy=0.86328125\n",
      "test accuracy = 0.8140000104904175\n",
      "step=13800, loss=0.39322733879089355, accuracy=0.84375\n",
      "test accuracy = 0.8125\n",
      "step=13900, loss=0.46364203095436096, accuracy=0.84375\n",
      "test accuracy = 0.8119999766349792\n",
      "step=14000, loss=0.4105941355228424, accuracy=0.859375\n",
      "test accuracy = 0.8084999918937683\n",
      "step=14100, loss=0.32088392972946167, accuracy=0.8671875\n",
      "test accuracy = 0.8059999942779541\n",
      "step=14200, loss=0.4359073042869568, accuracy=0.85546875\n",
      "test accuracy = 0.8029999732971191\n",
      "step=14300, loss=0.2936088442802429, accuracy=0.89453125\n",
      "test accuracy = 0.796500027179718\n",
      "step=14400, loss=0.35684648156166077, accuracy=0.875\n",
      "test accuracy = 0.7994999885559082\n",
      "step=14500, loss=0.3014499843120575, accuracy=0.89453125\n",
      "test accuracy = 0.8209999799728394\n",
      "step=14600, loss=0.4023076891899109, accuracy=0.84765625\n",
      "test accuracy = 0.7829999923706055\n",
      "step=14700, loss=0.4124603867530823, accuracy=0.8515625\n",
      "test accuracy = 0.7919999957084656\n",
      "step=14800, loss=0.3998134732246399, accuracy=0.84765625\n",
      "test accuracy = 0.8080000281333923\n",
      "step=14900, loss=0.3731290400028229, accuracy=0.87109375\n",
      "test accuracy = 0.815500020980835\n",
      "step=15000, loss=0.30623751878738403, accuracy=0.89453125\n",
      "test accuracy = 0.8144999742507935\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import os\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def one_hot_encoding(label):\n",
    "\n",
    "    '''\n",
    "    change label id to one-hot encoding\n",
    "    '''\n",
    "\n",
    "    values = np.asarray(label)\n",
    "    n_class = 4\n",
    "    encoding_result = np.eye(n_class)[values]\n",
    "    return encoding_result \n",
    "\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "\n",
    "    '''\n",
    "    load all of training data\n",
    "    '''\n",
    "\n",
    "    with open(file_path, \"r\") as lines:\n",
    "        data_list = []\n",
    "        for line in lines:\n",
    "            data_list.append(line.replace('\\n',''))\n",
    "\n",
    "        shuffle(data_list) \n",
    "\n",
    "    data_path = []\n",
    "    data_label = []\n",
    "    for data in data_list:\n",
    "        data_path.append(data.split(' ')[0])\n",
    "        data_label.append(int(data.split(' ')[1]))\n",
    "\n",
    "    return data_path, data_label\n",
    "\n",
    "\n",
    "def load_batch_data(data_path, labels):\n",
    "    \n",
    "\n",
    "    batch_data = []\n",
    "    for index, im in enumerate(data_path): \n",
    "        raw_image = Image.open(im)\n",
    "        ### please notice this line if image have already been normalized \n",
    "        resize_image = raw_image.resize((80, 80))\n",
    "        normalized_image = np.asarray(resize_image)/255.0\n",
    "        normalized_image = normalized_image.reshape(80,80,1)\n",
    "        batch_data.append(normalized_image)\n",
    "\n",
    "    batch_label = one_hot_encoding(labels)\n",
    "\n",
    "\n",
    "    batch_data = np.asarray(batch_data, np.float32)\n",
    "    batch_label = np.asarray(batch_label, np.float32)\n",
    "    return batch_data, batch_label\n",
    "\n",
    "\n",
    "\n",
    "print('loading image path......')\n",
    "train_data, train_label = load_data(\"train_data.txt\")\n",
    "test_data, test_label = load_data(\"test_data.txt\")\n",
    "\n",
    "\n",
    "print('number of train image is {}'.format(len(train_data)))\n",
    "print('number of test image is {}'.format(len(test_data)))\n",
    "\n",
    "\n",
    "'''\n",
    "set network parameters \n",
    "\n",
    "'''\n",
    "# 162*212\n",
    "image_size_width = 80\n",
    "image_size_height = 80\n",
    "num_labels = 4 # 4種\n",
    "num_channels = 1 # 黑白\n",
    "batch_size = 256\n",
    "kernel_size = 3\n",
    "num_steps = 15001\n",
    "\n",
    "'''\n",
    "create CNN model\n",
    "'''\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, image_size_height, image_size_width, num_channels],name='x')\n",
    "y = tf.placeholder(tf.float32, [None, num_labels],name='y')\n",
    "\n",
    "# initial variables\n",
    "layer1_weights = tf.Variable(tf.truncated_normal([kernel_size, kernel_size, num_channels, 32], stddev=0.1))\n",
    "layer1_biases = tf.Variable(tf.zeros([32]))\n",
    "layer2_weights = tf.Variable(tf.truncated_normal([kernel_size, kernel_size, 32, 64], stddev=0.1))\n",
    "layer2_biases = tf.Variable(tf.constant(1.0, shape=[64]))\n",
    "layer3_weights = tf.Variable(tf.truncated_normal([kernel_size, kernel_size, 64, 128], stddev=0.1))\n",
    "layer3_biases = tf.Variable(tf.constant(1.0, shape=[128]))\n",
    "\n",
    "layer4_weights = tf.Variable(tf.truncated_normal([12800, 1024], stddev=0.1))\n",
    "layer4_biases = tf.Variable(tf.constant(1.0, shape=[1024]))\n",
    "layer5_weights = tf.Variable(tf.truncated_normal([1024, num_labels], stddev=0.1))\n",
    "layer5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "# CNN model detail\n",
    "def model(input_image):\n",
    "    conv1 = tf.nn.conv2d(input_image, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv1 + layer1_biases)\n",
    "    pool1 = tf.nn.max_pool(hidden1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    conv2 = tf.nn.conv2d(hidden1, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden2 = tf.nn.relu(conv2 + layer2_biases)\n",
    "    pool2 = tf.nn.max_pool(hidden2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv3 = tf.nn.conv2d(hidden2, layer3_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden3 = tf.nn.relu(conv3 + layer3_biases)\n",
    "    shape = hidden3.get_shape().as_list()\n",
    "\n",
    "    reshape = tf.reshape(hidden3, [-1, shape[1] * shape[2] * shape[3]])\n",
    "\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer4_weights) + layer4_biases)\n",
    "    \n",
    "    return tf.add(tf.matmul(hidden, layer5_weights),layer5_biases,name=\"logis\")\n",
    "\n",
    "# build model\n",
    "logits = model(x)\n",
    "\n",
    "# define cost\n",
    "# with tf.name_scope('Loss'):\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits))\n",
    "\n",
    "# optimization\n",
    "# with tf.name_scope('Train'):\n",
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "# show prediction result\n",
    "prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "\n",
    "# 初始化 Graph\n",
    "# init = tf.global_variables_initializer()\n",
    "# sess = tf.Session()\n",
    "\n",
    "# 將視覺化輸出\n",
    "# writer = tf.summary.FileWriter(\"TensorBoard/\", graph = sess.graph)\n",
    "\n",
    "# 開始運算\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('start training......')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (len(train_data) - batch_size)\n",
    "        batch_data_path = train_data[offset:(offset + batch_size)]\n",
    "        batch_label_path = train_label[offset:(offset + batch_size)]\n",
    "\n",
    "        train_batch_data, train_batch_labels = load_batch_data(batch_data_path, batch_label_path)\n",
    "\n",
    "\n",
    "        feed_dict = { x: train_batch_data, y: train_batch_labels}\n",
    "        _, l, train_accuracy_ = sess.run([optimizer, loss, accuracy], feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "        if (step % 100 == 0):\n",
    "            saver.save(sess, \"train_model/model.ckpt\")\n",
    "            print('step={}, loss={}, accuracy={}'.format(step, l, train_accuracy_))\n",
    "            test_batch_data, test_batch_labels = load_batch_data(test_data[:2000], test_label[:2000])\n",
    "            feed_dict = { x: test_batch_data, y: test_batch_labels}\n",
    "            test_accuracy_ = sess.run(accuracy, feed_dict=feed_dict)\n",
    "            print('test accuracy = {}'.format(test_accuracy_))\n",
    "    \n",
    "    #print('start testing......')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_batch_data(data_path):\n",
    "    \n",
    "\n",
    "#     batch_data = []\n",
    "#     for index, im in enumerate(data_path): \n",
    "raw_image = Image.open('kermany2018/NewSize/test/CNV/CNV-53018-1.jpeg')\n",
    "### please notice this line if image have already been normalized \n",
    "resize_image = raw_image.resize((80, 80))\n",
    "normalized_image = np.asarray(resize_image)/255.0\n",
    "normalized_image = normalized_image.reshape(80,80,1)\n",
    "#         batch_data.append(normalized_image)\n",
    "\n",
    "#     batch_label = one_hot_encoding(labels)\n",
    "\n",
    "\n",
    "batch_data = np.asarray(normalized_image, np.float32)\n",
    "batch_data=batch_data.reshape(1,80,80,1)\n",
    "#     batch_label = np.asarray(batch_label, np.float32)\n",
    "#         return batch_data\n",
    "print(batch_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# saver = tf.train.import_meta_graph('train_model/model.ckpt.meta')\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess,\"train_model/model.ckpt\")    \n",
    "#     test_accuracy_ = sess.run(logits, feed_dict={x:batch_data})\n",
    "    test_batch_data, test_batch_labels = load_batch_data(test_data[:2000], test_label[:2000])\n",
    "    feed_dict = { x: test_batch_data, y: test_batch_labels}\n",
    "    test_accuracy_ = sess.run(accuracy, feed_dict=feed_dict)\n",
    "    print('test accuracy = {}'.format(test_accuracy_))\n",
    "# sess.run(logits, feed_dict={x:batch_data}) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
